#  Kafka Performance Benchmark Lab on GKE

![Tech Stack](https://img.shields.io/badge/Tech-Kubernetes%20%7C%20Kafka%20%7C%20Strimzi%20%7C%20Prometheus%20%7C%20Locust-blue)
![Cloud](https://img.shields.io/badge/Cloud-GCP%20%7C%20GKE-orange)
![License](https://img.shields.io/badge/License-MIT-green)

Este projeto implementa um laborat√≥rio completo de Engenharia de Dados para realizar testes de carga (*stress testing*) em um cluster Apache Kafka de alta disponibilidade, orquestrado pelo Strimzi no Google Kubernetes Engine (GKE).

O objetivo √© ir al√©m da simples implanta√ß√£o, focando em **medir, analisar e otimizar** o *throughput* (vaz√£o) e a lat√™ncia sob diferentes configura√ß√µes de produtor, utilizando testes de carga distribu√≠dos com Locust.

## üèõÔ∏è Arquitetura

O ambiente √© composto por um ecossistema de ferramentas padr√£o de mercado, integradas para fornecer uma plataforma robusta de teste e observabilidade.

```mermaid
graph TD
    subgraph GKE Cluster [Google Kubernetes Engine]
        subgraph Monitoring [Namespace: monitoring]
            Prometheus(Prometheus Operator) --> Grafana(Grafana);
        end

        subgraph KafkaCluster [Namespace: kafka]
            Strimzi(Strimzi Operator) --> Kafka(3x Kafka Brokers);
            Strimzi --> Zookeeper(3x ZK Nodes);
        end

        subgraph LoadTesting [Namespace: kafka]
            LocustMaster(Locust Master) <--> LWorkers(10x Locust Workers);
        end

        Prometheus -- Scrapes Metrics --> Kafka;
        Grafana -- Queries --> Prometheus;
        LWorkers -- Produces Messages --> Kafka;
    end

    User(üë®‚Äçüíª Engenheiro) -- Acessa UI --> Grafana;
    User -- Inicia Teste --> LocustMaster;
```

## ‚ú® Features

- **Infraestrutura como C√≥digo:** Setup do cluster GKE automatizado via script.
- **Gerenciamento Declarativo:** Cluster Kafka e Zookeeper gerenciados pelo Strimzi Operator.
- **Observabilidade Completa:** M√©tricas JMX do Kafka expostas para Prometheus e visualizadas em dashboards Grafana customizados.
- **Teste de Carga Distribu√≠do:** Swarm de Locust rodando dentro do Kubernetes para gerar alta carga sem gargalos de rede externa.
- **An√°lise de Performance:** Metodologia de teste para avaliar o trade-off entre Vaz√£o (Throughput), Lat√™ncia e Durabilidade.

## ‚öôÔ∏è Tech Stack

- **Cloud/Containeriza√ß√£o:** Google Cloud Platform (GCP), GKE, Docker.
- **Orquestra√ß√£o:** Kubernetes, Helm.
- **Apache Kafka:** Strimzi Operator, Kafka Brokers, Zookeeper.
- **Teste de Carga:** Locust, Python, Confluent Kafka Client.
- **Monitoramento:** Prometheus Operator, Grafana.

## üöÄ Guia de Setup e Execu√ß√£o

Siga os passos abaixo para recriar o ambiente de benchmark.

### Pr√©-requisitos
- `gcloud` CLI autenticado
- `kubectl`
- `helm`
- `docker`

### 1. Provisionar a Infraestrutura
O script `setup-infra.sh` cria o cluster GKE com n√≥s otimizados e um StorageClass SSD.
```bash
chmod +x setup-infra.sh
./setup-infra.sh
```

### 2. Instalar Operadores
Instalamos os operadores Strimzi (para o Kafka) e Prometheus (para monitoramento).
```bash
# Strimzi Operator
kubectl create namespace kafka
helm repo add strimzi https://strimzi.io/charts/
helm install strimzi-operator strimzi/strimzi-kafka-operator -n kafka --version 0.40.0

# Prometheus & Grafana
kubectl create namespace monitoring
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm install prometheus prometheus-community/kube-prometheus-stack -n monitoring
```

### 3. Implantar o Cluster Kafka e a Observabilidade
Aplicamos os manifestos para criar o cluster Kafka, o usu√°rio, o t√≥pico e o `PodMonitor` que conecta o Kafka ao Prometheus.
```bash
kubectl apply -f k8s/metrics/kafka-metrics.yaml
kubectl apply -f k8s/kafka-cluster.yaml
kubectl apply -f k8s/kafka-topic.yaml
kubectl apply -f k8s/kafka-user.yaml
kubectl apply -f k8s/pod-monitor.yaml
```

### 4. Preparar e Implantar o Locust Swarm
Constru√≠mos uma imagem Docker customizada para o Locust com as depend√™ncias necess√°rias e a implantamos no cluster.

```bash
# 1. Construir e enviar a imagem Docker customizada
# (Substitua <seu-usuario-dockerhub> pelo seu usu√°rio)
docker build -t <seu-usuario-dockerhub>/kafka-locust:1.0 .
docker push <seu-usuario-dockerhub>/kafka-locust:1.0

# 2. Atualize a imagem no arquivo k8s/locust-swarm.yaml

# 3. Crie os segredos e implante o Locust
kubectl create configmap locust-script -n kafka --from-file=src/locustfile.py
kubectl create secret generic kafka-locust-secret -n kafka --from-literal=password='<SUA_SENHA_KAFKA>'
kubectl apply -f k8s/locust-swarm.yaml

# 4. Obtenha o IP para acessar a UI do Locust
kubectl get svc locust-master-svc -n kafka
```

## üìä Relat√≥rio Benchmark de Performance

## Resumo Executivo

Este relat√≥rio detalha o benchmark de performance de um cluster Apache Kafka no GKE, visando otimizar a configura√ß√£o do produtor Python para diferentes cargas de trabalho. A configura√ß√£o de **Baseline** (`batch.size=64KB`, `linger.ms=10`) estabeleceu uma base s√≥lida com vaz√£o de **~7.500 msg/s** e lat√™ncia m√©dia est√°vel.

A otimiza√ß√£o para **Alta Vaz√£o** (`batch.size=128KB`) foi a mais eficiente: elevou o throughput para picos de **~10.000 msg/s** (+30%) enquanto **reduziu drasticamente o uso de CPU** nos brokers (de 18% para 5%), tornando-a ideal para ingest√£o de dados em massa com baixo custo.

Por outro lado, o teste de **Baixa Lat√™ncia** (`linger.ms=0`) revelou-se contraproducente para alto volume: a tentativa de envio imediato congestionou a rede, **triplicando a lat√™ncia** e elevando o consumo de CPU, provando que o *batching* √© indispens√°vel para a estabilidade do sistema.

---

### An√°lise Detalhada por Cen√°rio

Para validar a capacidade e o comportamento do cluster sob diferentes requisitos de neg√≥cio, executamos 4 cen√°rios de testes distintos variando as configura√ß√µes do **Producer (Locust)**.

### Cen√°rio 1: Baseline (Configura√ß√£o Balanceada)
* **Configura√ß√£o:** `batch.size=64KB`, `linger.ms=10`, `acks=1`, `compression=lz4`.
* **Objetivo:** Estabelecer um ponto de partida com foco em equil√≠brio entre lat√™ncia e vaz√£o.

| Locust Charts | Grafana Dashboard |
| :---: | :---: |
| <img src="img/Locust-base.png" alt="Locust Baseline" width="100%"> | <img src="img/grafana_base.png" alt="Grafana Baseline" width="100%"> |

**Resultados:**
* **Throughput:** Atingimos uma vaz√£o consistente de **~7.500 mensagens/segundo (RPS)** sem erros de entrega.
* **Lat√™ncia:** Ap√≥s o *ramp-up* inicial, a lat√™ncia m√©dia se manteve est√°vel em **~200ms**.
* **Efici√™ncia:** O uso de CPU nos brokers ficou em torno de **15% a 18%** (0.15 vCPU), indicando folga para escalar. O uso de compress√£o **LZ4** manteve a entrada de rede baixa (~279 kB/s), otimizando custos.

---

### Cen√°rio 2: High Throughput (Lotes Maiores)
* **Configura√ß√£o:** `batch.size=128KB` (Dobrado), `linger.ms=10`.
* **Hip√≥tese:** Aumentar o tamanho do lote reduzir√° o overhead de I/O e CPU, permitindo maior vaz√£o.

| Locust Charts | Grafana Dashboard |
| :---: | :---: |
| <img src="img/teste2/teste2_BS131072.png" alt="Locust High Throughput" width="100%"> | <img src="img/teste2/teste2.png" alt="Grafana High Throughput" width="100%"> |

**Resultados:**
* **Throughput:** Atingimos uma vaz√£o consistente de **~7.500 mensagens/segundo (RPS)** sem erros de entrega.
* **Lat√™ncia:** Ap√≥s o *ramp-up* inicial, a lat√™ncia m√©dia se manteve est√°vel em **~200ms**.
* **Efici√™ncia:** O uso de CPU nos brokers ficou em torno de **15% a 18%** (0.15 vCPU), indicando folga para escalar. O uso de compress√£o **LZ4** manteve a entrada de rede baixa (~279 kB/s), otimizando custos.

---

### Cen√°rio 3: Low Latency (Envio Imediato)
* **Configura√ß√£o:** `linger.ms=0` (Sem espera), `batch.size=64KB`.
* **Hip√≥tese:** Remover o tempo de espera entregar√° mensagens mais r√°pido.
  
| Locust Charts | Grafana Dashboard |
| :---: | :---: |
| <img src="img/teste2/teste3/teste3_linger0.png" alt="Locust Low Latency" width="100%"> | <img src="img/teste2/teste3/teste3.png" alt="Grafana Low Latency" width="100%"> |

**Resultados (Degrada√ß√£o):**
* **Lat√™ncia:** Ao contr√°rio do esperado, a lat√™ncia m√©dia **triplicou para ~600ms**. O envio de pacotes min√∫sculos congestionou a rede e a fila de processamento.
* **Custo de CPU:** O uso de CPU saltou para **~35%** (aumento de 7x comparado ao Cen√°rio 2), pois os brokers tiveram que processar milhares de requests individuais.
* **Conclus√£o:** `linger.ms=0` √© contraindicado para streaming de alto volume. O *batching* (mesmo que pequeno, 5-10ms) √© essencial para estabilidade do cluster.
  
---

### Cen√°rio 4: Max Durability (Seguran√ßa Total)
* **Configura√ß√£o:** `acks=all` (Confirma√ß√£o de todas as r√©plicas).
* **Hip√≥tese:** Garantir persist√™ncia em todas as r√©plicas evitar√° perda de dados, mas custar√° performance.

| Locust Charts | Grafana Dashboard |
| :---: | :---: |
| <img src="img/teste2/teste3/teste4/teste4_acks_alll.png" alt="Locust Max Durability" width="100%"> | <img src="img/teste2/teste3/teste4/teste4.png" alt="Grafana Max Durability" width="100%"> |

**Resultados:**
* **Impacto na Vaz√£o:** O throughput caiu cerca de **30%** em rela√ß√£o ao Baseline (de 7.5k para **~5.400 RPS**), um "imposto" aceit√°vel para garantir durabilidade zero-loss.
* **Custo Computacional:** O uso de CPU disparou para **~90% de 1 vCPU** (quase satura√ß√£o), indicando que a replica√ß√£o s√≠ncrona √© intensiva para o processador.
* **Conclus√£o:** Use `acks=all` apenas para dados cr√≠ticos (transa√ß√µes financeiras). Para logs ou m√©tricas, o custo extra de hardware pode n√£o se justificar.

---

### Tabela Comparativa

| Cen√°rio | Configura√ß√£o | RPS M√©dio | Lat√™ncia M√©dia | Uso de CPU (Broker) | Veredito |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **1. Baseline** | Batch 64KB / Acks 1 | ~7.500 | ~200ms | 15% | ‚úÖ Equilibrado |
| **2. Throughput** | Batch 128KB | ~7.000 (Pico 10k) | ~170ms | **5% (Melhor)** | üöÄ Mais Eficiente |
| **3. Latency** | Linger 0ms | ~4.700 | ~600ms | 35% | ‚ùå Inst√°vel |
| **4. Durability** | Acks All | ~5.400 | ~200ms | **90% (Pior)** | üõ°Ô∏è Mais Seguro |

### Conclus√£o Final e Recomenda√ß√µes

* **Trade-off Central:** Os testes validaram o trade-off cl√°ssico de sistemas distribu√≠dos: o agrupamento de dados (*batching*) maximiza a vaz√£o e efici√™ncia, enquanto o envio imediato sobrecarrega a infraestrutura. O equil√≠brio ideal depende estritamente do SLA da aplica√ß√£o.

* **Recomenda√ß√£o Principal (Data Engineering):** Para a ingest√£o massiva de logs, m√©tricas e Data Lakes, a configura√ß√£o de **Alta Vaz√£o (Cen√°rio 2)** √© a vencedora indiscut√≠vel. Ela entregou o maior throughput (~10k RPS de pico) com apenas ~5% de uso de CPU, provando ser a arquitetura mais sustent√°vel e econ√¥mica (Green IT).

* **Recomenda√ß√µes Secund√°rias:**
    * **Sistemas Cr√≠ticos:** Para fluxos financeiros ou de auditoria, a configura√ß√£o de **Durabilidade (Cen√°rio 4)** com `acks=all` √© mandat√≥ria, aceitando-se o custo de ~30% na vaz√£o e maior uso de CPU.
    * **Lat√™ncia Sens√≠vel:** O teste demonstrou que remover totalmente o buffer (`linger.ms=0`) √© contraproducente em alta carga, pois gerou congestionamento. Para baixa lat√™ncia, recomenda-se manter um **batching m√≠nimo** (ex: `linger.ms=5`) em vez de zero, para garantir fluxo cont√≠nuo sem engargalar a rede.

## üßπ Limpeza do Ambiente (Teardown)

Para evitar cobran√ßas indesejadas no Google Cloud (GCP), √© obrigat√≥rio destruir o cluster e os discos persistentes que o Kafka utilizou.

Execute os comandos abaixo na ordem:

```bash
# 1. Deletar o Cluster Kubernetes
# (Isso para a cobran√ßa das m√°quinas virtuais/n√≥s)
gcloud container clusters delete kafka-bench --zone us-central1-a --quiet

# 2. Deletar Discos SSD √ìrf√£os (CR√çTICO)
# (O GKE n√£o deleta os discos de dados automaticamente. Se pular isso, voc√™ ser√° cobrado pelo armazenamento)
gcloud compute disks list --filter="name~^gke" --zones us-central1-a --format="value(name)" | xargs -I {} gcloud compute disks delete {} --zone us-central1-a --quiet
```

## üìÑ Licen√ßa
Este projeto est√° sob a licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes.
